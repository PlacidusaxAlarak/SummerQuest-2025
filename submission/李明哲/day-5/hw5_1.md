# 答题卡

## 1 并行策略与张量 shape

### 1.1

#### 1.1.1
每个 rank 上的权重矩阵 $W_1^{(i)}$ 的 shape 是 $\mathbb{R}^{d \times \frac{4d}{P}} = \mathbb{R}^{1024 \times 1024}$

#### 1.1.2
每个 rank 输入的张量 $X$ 的 shape 是 $\mathbb{R}^{B \times S \times d} = \mathbb{R}^{8 \times 128 \times 1024}$

#### 1.1.3
每个 rank 本地输出 $Y_i$ 的 shape 是 $\mathbb{R}^{B \times S \times \frac{4d}{P}} = \mathbb{R}^{8 \times 128 \times 1024}$

最终的完整输出 $Y$ 通过将所有 rank 的 $Y_i$ 在最后一个维度上拼接得到：$Y = [Y_0, Y_1, Y_2, Y_3]$，shape 为 $\mathbb{R}^{8 \times 128 \times 4096}$

### 1.2

#### 1.2.1
每个 rank 上的权重矩阵 $W_2^{(i)}$ 的 shape 是 $\mathbb{R}^{\frac{4d}{P} \times d} = \mathbb{R}^{1024 \times 1024}$

#### 1.2.2
每个 rank 接受输入的张量的 shape 是 $\mathbb{R}^{B \times S \times \frac{4d}{P}} = \mathbb{R}^{8 \times 128 \times 1024}$

#### 1.2.3
每个 rank 本地输出 $Z_i$ 的 shape 是 $\mathbb{R}^{B \times S \times d} = \mathbb{R}^{8 \times 128 \times 1024}$

最终的完整输出 $Z$ 通过对所有 rank 的 $Z_i$ 进行 AllReduce（求和）得到：$Z = \sum_{i=0}^{3} Z_i$

## 2 通信分析

### 2.1

#### 2.1.1
前向传播不需要通信。

- 通信操作：无
- 通信量：0

#### 2.1.2
反向传播时，计算 $\partial L / \partial X$ 需要通信。

原因：由于每个 rank 只计算了部分输出通道的梯度 $\partial L / \partial Y_i$，而要得到完整的输入梯度 $\partial L / \partial X$，需要将所有 rank 的局部梯度贡献相加。具体来说，$\partial L / \partial X = \sum_{i=0}^{P-1} \partial L / \partial Y_i \cdot (W_1^{(i)})^T$，因此需要 AllReduce 操作。

通信量：$B \times S \times d \times \text{sizeof(float)} = 8 \times 128 \times 1024 \times 4 = 4\text{MB}$

### 2.2

#### 2.2.1
前向传播需要通信。

- 通信操作：AllReduce（求和）
- 通信量：$B \times S \times d \times \text{sizeof(float)} = 8 \times 128 \times 1024 \times 4 = 4\text{MB}$

#### 2.2.2
反向传播时，计算 $\partial L / \partial X$ 不需要通信。

原因：在 Row Parallel 中，每个 rank 接收完整的输出梯度 $\partial L / \partial Z$，可以独立计算自己负责的输入通道的梯度 $\partial L / \partial X_i = \partial L / \partial Z \cdot W_2^{(i)}$。由于输入已经是切分的，无需额外通信。

# 3 如果两层都使用 Row Parallel，会产生哪些额外通信？两层都使用 Column Parallel 会带来什么问题？

**两层都使用 Row Parallel 的问题：**
- Linear1 的输出需要 AllReduce 得到完整的中间激活
- 但 Linear2 的 Row Parallel 需要切分的输入，因此需要额外的 AllToAll 或 Scatter 操作将完整激活重新切分
- 这会导致额外的通信开销：AllReduce + Scatter

**两层都使用 Column Parallel 的问题：**

- Linear1 输出是切分的（每个 rank 持有部分输出通道）
- 但 Linear2 的 Column Parallel 需要完整的输入，因此需要 AllGather 操作
- Linear2 的输出也是切分的，可能需要再次 AllGather 得到完整输出
- 这会导致额外的通信开销：AllGather（可能多次）
